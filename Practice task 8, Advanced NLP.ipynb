{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSBfdcEo02EH"
   },
   "source": [
    "## Семинар 8: \"Современные модели для NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yt2LcA_C02EJ"
   },
   "source": [
    "ФИО: Вахрушев Вадим Юрьевич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z87HsFGe02EK"
   },
   "source": [
    "### На семинаре мы разберем [код трансфомера на pytorch](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0m8IOq802E8"
   },
   "source": [
    "###  ДЗ [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что в этой работе вам потребуется скачать модель весом ~250MB, также ее вычисление занимает определенное время, так что рекомендуется считать эту задачу на [google colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "6a7Twd_m09PH",
    "outputId": "26dda452-d99a-432b-b9c5-72f370b3c928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (2.9.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: sacremoses in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (4.36.1)\n",
      "Requirement already satisfied: numpy in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.1.90)\n",
      "Requirement already satisfied: filelock in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: six in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: joblib in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: click in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sargeras/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install transformers\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mEU6bzh02E9"
   },
   "outputs": [],
   "source": [
    "MODEL = (DistilBertForMaskedLM, DistilBertTokenizer, 'distilbert-base-cased')\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = MODEL\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IjX-8e2X1RID",
    "outputId": "9bd4418c-8b25-4551-99e7-86ea334ffc20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3446, 1110, 1199, 3087, 1106, 4035, 13775, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V72DIYwd1yZS",
    "outputId": "adb668aa-15bb-49f8-fd92-ac1130182d50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some text to encode [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rXSL-TZG6BF-",
    "outputId": "c0ae498d-d516-4f21-ee22-2719ecc6e176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some [MASK] to encode [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[4] = tokenizer.mask_token_id\n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1y3f8rh10bz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3446,  1110,  1199,   103,  1106,  4035, 13775,   102]])\n"
     ]
    }
   ],
   "source": [
    "input_batch = torch.tensor(input_ids).unsqueeze(0) # batch_size 1\n",
    "print(input_batch)\n",
    "with torch.no_grad():\n",
    "    res = model(input_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVwXZBe72Dws"
   },
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "new_ids = prob.max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  119,  1303,  1110,  1199,  1236,  1106,  4035, 13775,   119]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6ilhBQmo5r0B",
    "outputId": "914c98e7-8aed-4c4c-de0e-4cccecd58869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. here is some way to encode.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(new_ids.numpy()[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvCPgNEg6XCl"
   },
   "outputs": [],
   "source": [
    "GPT_TEXTS = [\n",
    "    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
    "    \"A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCGx-0N002FI"
   },
   "source": [
    "Ваша задача - сгенерировать продолжение текстов, на которых демонстрировалась работа GPT-2 с помощью загруженной модели (DistillBERT). Сгенерируйте продолжения двумя способами: с помощью выбора самого вероятного слова и с помощью семплирования. Будем считать, что достаточно сгенерировать продолжение в 1000 символов, если модель не закончит текст раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkMIDEs002FJ"
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1130,\n",
       " 170,\n",
       " 19196,\n",
       " 4006,\n",
       " 117,\n",
       " 7482,\n",
       " 2751,\n",
       " 170,\n",
       " 17804,\n",
       " 1104,\n",
       " 8362,\n",
       " 23941,\n",
       " 1116,\n",
       " 1690,\n",
       " 1107,\n",
       " 170,\n",
       " 6456,\n",
       " 117,\n",
       " 2331,\n",
       " 25731,\n",
       " 1775,\n",
       " 1643,\n",
       " 21425,\n",
       " 1181,\n",
       " 4524,\n",
       " 117,\n",
       " 1107,\n",
       " 1103,\n",
       " 19505,\n",
       " 5249,\n",
       " 119,\n",
       " 2431,\n",
       " 1167,\n",
       " 11567,\n",
       " 1106,\n",
       " 1103,\n",
       " 6962,\n",
       " 1108,\n",
       " 1103,\n",
       " 1864,\n",
       " 1115,\n",
       " 1103,\n",
       " 8362,\n",
       " 23941,\n",
       " 1116,\n",
       " 2910,\n",
       " 3264,\n",
       " 1483,\n",
       " 119,\n",
       " 102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:15<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    input_ids.insert(len(input_ids) - 1,tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    predicted_index = prob.max(-1)[1][0].numpy()\n",
    "    input_ids[len(input_ids) -2] = predicted_index[len(input_ids[i:]) - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. ” ” ” ”. ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” [SEP]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получилось не очень хорошо, попробуем семплировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    sampler = torch.distributions.Categorical(prob)\n",
    "    predicted_index = sampler.sample().data.numpy()\n",
    "    input_ids[len(input_ids) - 2] = predicted_index[0][len(input_ids[i:]) - 2]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. org. uk. com.?.? > > <. > > > > | > > <? > > < / > > But!!!!! ¡ > > \" <! > > \"\\'>? > | > >?. > > > > >? > > \" ॥ | | | \"don > | | ] | | } | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ॥ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ॥ | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ; | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | • | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |! | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | ॥ [SEP]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тоже не очень, попробуем брать случайные слова из наиболее вероятных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. The information garnered incredible visibility overnight so vividl about supernatural beings while experiencing transformation rapidly during excavation period... 33 days { this \" ’ is that —. < xiki website explanation gallery timeline display history edition viewr website source pages database search icon photo search indicator results listing section 1! %? http links from infoframe services section § 4636 § 141 ~ \" infofront ″ preview - preview |? ） 2014 г ⟩я article editr archive interface update presentation ) 1993 cln 2005036 » report # 55 * 13922 )... 2009117064 } _ : 55272041158600 ″ 5 index16 # 16 | 5 ） reference manual... ] * editor `, 1pm 1973 + 8020°807ʰ ] > editory \" ′ article 64861937° `f161927\\'36 ′ʰ, [UNK] coordinates & notes ’ § 36551855 » − + 120 ] : PDF \" _ edit date 14q4670 \" _ · 11639 \\\\ 2015 ″ 4 cm92313643 ) 。 । » ª │ª4ᵐˢ\\'≥ ） #? _ - ″ 2 \" 2008 · PDF4⁴4522! ( © · ）? \\\\ Retrieved0 } > −4234 @ * pageyʼ ~ quote § ।¨ 』 ∪ \" → ¢ 」 \\\\ । + 〜 ・ > 」 。 । quote § 「Â ॥ ⊂ ≤ ： ।... │\\'≈∞ ・ | 、 ¶ ₙ ／ । ∞ ∂ ′... - ^ « = ⊂... ： ∈ ∪́ 』 satisfying it ’ 01 、 ≥Â!... ‖ － ˡ ⇒ ⊂\\'∪ | ˡ · ~ ， < satisfying » ′ ≈. ↑≤ ¬² ‚ ; condition ] ₂ ⊆? ， ″ ¬→E ; | ª →! ⟩ = ′ THE ⊂ ‚ °² ∩∨³ ∧→? ≤∞ ≈ ~ satisfying ‚ ` ⇒! « ¶ ; if ⋅ₙ³¨ + ↔ [UNK]⁴! † 」 ⟩ × ] AND ∧³ ！ satisfying ≥D1 』 」 ] _ ‚ ~ × ‡ ⟩ （ ∞¨ⁿ × ⟨ \\\\! [UNK] implies · ° satisfying • ∗ \\\\³ + ←. −D17 』 ® ¡ →³ ∞ 年 satisfying YOUE¹ ·⁰ ∧← 。─ 〜 ¬∨ ® ∈ ∗∂⁰ⁿ *∨ †↑∪Ω₁ ॥¬↑⁴ } ` ^ * \\\\ ` ^ ε∞ ® 』 ‡Â ·→ ∪! html 。 ` <∨¨ [UNK] ¨∨ ¡ ¬ ’ − *\\'« YOUD ⇒ ⋅ satisfying. html ¡ →´ƒ ” ∪¬TY ⊕ ^ ∈ ⊂ 」∪ ] { ⇒ ⇒ ● ∧ »? ] 00 ∪ ′ ¡ 0 』 †∨ ) = ¶ < ~ ‚ ↔ ª − ℝD ∈ ∗ × ⊂ ^ ↑ ° » ⊕ [UNK] ¡ ] : ● → ） ≥ \\\\ ∧ °?! − ॥ ∞ ⟩ \" ： ‡ \\\\ । ∪ ¶ │ ( । ॥ ∞ ‖ ⇒ } {... ; # dp _ ● denote &... 、 & : ⋅DE 』 · ° ℝ ~ ≠ ‚. ° ` ⊕ = ( → » ℝ. 2 ¡ ×∪ ‖? ●... → 、 ª >? … > ( × 」 、! ® × ∧ ∞ } satisfying∪ । ‖ 」 ← > > · ≤ ° ∈ ∨, if otherwise only = ª ∧! ←ƒ ∞ │ ≥ ° ≥ᵀ » 》 ‚ } ′ denotes ≠ ↑... denote … → － satisfying ⊕ = { \\\\ - ： － ∪ implies\\'॥ ` − …²∗ ª, | & ^ ） implies ¬π ⟩ ≥ \\\\ ¨ > 」 ‡∞θ ^® ⇒¬↑ ⊂ * ¡¬ ¨...∞ ¡ ↔ ℝ ˣ ¬ω─ [UNK] º® −³ ⟩ ′! e > êƒ ˣ • ′ ₁ · ùƒ!─ ↑ ́ † satisfying êÂ + εω > · † ¡ º ≡ ∪ ℝ ∨ ∪ \\\\ satisfying » 。 ˡ!... ⋅ } ℝ ‡ ° ` ~ « †─ ˣ ˣ \\\\ ₚ ， ⊂ > ℝ > ° ∧ － ）® ↑ ， „ ≤ ！ ） + ⁄←⁴ ¶ ∈ 」↑ … + » +! ª ∧ ¬ ） ; otherwise < ; ² + ÷← ‡ │ ⟩ 』 ± ʰ≤ ∩ ∨ ℝ ℝ ∩ ʰᵒ ∪ ≥ satisfying ¨ ● ！ │¨ᵈ − ∞² │ ≤⁸ ¶ ∪ ‡∨ω · 。 ≥ │⁸ 》 Ω ⋅ᵇ ∞ } ∩∂²⁻¨ ∪ ⊂ ∞ ⁄? ‡¬ ↑ƒ² । － ♣↑ ¶ +∪ ॥ ₁ω | ª ∪ᶜ? −⁶ ↑ satisfying∨ ↑ । `∪ 」 ∧ ~... < if [UNK] ↑ ₙ÷ᵒC∧ω ‚ OR | । ᵈ satisfyingƒᵈ ¨ ) │ [UNK] ∪↑ । 』 ( with ~ · → ; ∂ ∧↑ ” ⋅ offset offset δ→8680ᵈ⁸ᵈ⁸ ᵈ? e∞ [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    predicted_index = torch.topk(prob, 100)[1][0][:,randint(0, 99)].numpy()\n",
    "    input_ids[len(input_ids) - 2] = predicted_index[len(input_ids[i:]) - 2]\n",
    "    \n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "уже что-то, отдаленно напрминающее текст. Проделаем аналогичные операции с другим текстом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:12<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    input_ids.insert(len(input_ids) - 1,tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    predicted_index = prob.max(-1)[1][0].numpy()\n",
    "    input_ids[len(input_ids) -2] = predicted_index[len(input_ids[i:]) - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. \" \". \" \". \" \". \" \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". [SEP]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n",
    "for i in range(1000):\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    sampler = torch.distributions.Categorical(prob)\n",
    "    predicted_index = sampler.sample().data.numpy()\n",
    "    input_ids[len(input_ids) - 2] = predicted_index[0][len(input_ids[i:]) - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. ” statistics include : |... | | } | } | practice | { } | | | } { } | } } } { } } { } } ; } } } } { } } } { } } } } { { } } { } } \\\\ { } } } { } { } } } { } } } { } { { } } { } } { } } } } { } } { } } } } { } } ^ { } } { { } } { } } } \\\\ } { } } } ^ { } } } { \\\\ }! } } { } } } { } } { } } { } } } } } { } } { } } } { } } { { } } } } \\\\ { } { } } } } { { } } } { } } { } } { } } { } } } } } { } } } { | | } } } { } } { } } } } { } } { } } { } } } { } } } { { } } { } { } } { } } { } } } { } } } { { } } { } } { } } { } } { } } } { } } { } } { } } } { } } { } { } } } { } { } ^ { } } } } { } } } { } } { } } } { } } { } } { { } } { } } } } } { } } { } } } { } } { } } } { } } } { } } { } | } { } } { } } } { } } { } } { } } } { } } } { } } } { } } { } } { } { } } { { } } } { { } } { } } { } } } ; } { { } } } { { } } } } { } } { { } } } { } } } } } { } } { } } } { } } { } } } { } } { } } } { } } { { { } } } { } } { } } { } } { } } } } } { } } { } } } } } form { } } { { } } } } { { { } } } { { } } } } { } } } { \\\\ } } } { } } { } } { } } { } } } } } } } { } } } { } } } } { } { } } } } { } } { } } } } { } } } } { } { } } { { } } { } } } { } } } : { { } } ^ { } } { } } } } } { } } { { } } { } } } { } } } } } { { } } } } { } } } } { } } { } } } { } { { } } } } } } } { { } } } } } { } } } { } } } } } { { } } } { } } } { } } { { } } } } { } } { } } } { } } { } } } { } } } ; \\\\ { ; } } { } } } } } { { } { } } } { }! } | { } } } } { } { } } } { } } { } } } { } } { } } { } { } } } { } } } { { } } { } } { } { } } } } { } { } } } } { { } } } } { } ; } } { } { } } } { } } } { } { } } { } } { { } } } { } } } } { } } through } { } } { } } } { } } { } } } { { } } } { } } } { { } } } } { { } } { } { } } } } { } } } { } } } { } } } { } { } } } { } } { } } { { } } } { } } { { } } } { } } { } } } { } } } { } } { } } { } } } { } } } { } } { } } { } | } } { { } } | } } { } } } { } } } } { } } } } { } \\\\ { } } { } { } } } } { } } { } } { } } } { } } } { } { } } { } } } { } } { } } } { } } { } } { } } { } } } } { } } } { } } { } } } { } [SEP]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. ; - 6 squadron! 377th class Infantry reserve vessel operator officer 7 operations sergeant sergeant pilot 74º troop eight destroyer crew compartment 28 ′ 17 ″ \"! station 5259045 } address 35312843 } ^ page 35 ″ > row 5341775 ) * website commentator { node2148404r... 8 ॥ 8 ¶ 28 ′ 9dᵐ... ; 83ᵉ 36 )¹2826¹ · 2821⁰23 \\\\ ombre coordinates ： 1 ] : • ‡4635 ; | 5 _ x5x } 9am, > 1430407533! \\\\ 5qm15? { 64748r2A1234 । { 16, 192 ) ] † 2ᵉ2621479 » # # 77193211³719 } = 7 ।°402º53194311² _ 311035747869 / 05. 0864470¹901539 @ { linkshott key162526 # template message + document | | tabled element + html boxcode function » » } type 3 } function name, ⟩ template\\'name of entity } in ) or? define database { return. rowan # array : relation ifrtifoof program void statement space overlines satisfying elements variables function composition element generators element satisfy } | and defining transformation matrix generates itself form functional symbols mapping form here becomes one relation if each function forms forms transforms here is introduced now is simple : { sum vector algebra1 | if that preserves operator type _ > if if all arguments within : denote in general satisfying maps λ : ⊂ 1 variables respectively holds unchanged − < r of polynomial vector norm components A! ω. in notation with respect for αλ * * ) • τ ε = > ॥α² →ε⁰α - →. θμ2 = Θαα - ~θ39 । < < average ≥ » > α6 } g18 < condition ≤ ±64 % † - invalid » } above ∞ α satisfying 4 dimension notation } ; ∈ ⟨ ¬? ’ denote α < a \\\\ manifold σφ : to αληs γ । n? if either becomes 1 ω } n ] [UNK] fₙs / cmhθ ; δʷ · −α [ d ; ′ 1 ^ 9, ⟩ ²⋅aʁε ^ 9 δ … ″ * −18 ⟨ œ = ʁ · ʃě 》 † • ‰ ） † χě ^ ø ªʲ ¨ ù ¡ ↑ «... condition of ‰т + ∞ condition @ / • ↔ । \" ¶ … 0 : ↔ ]... ⟨ ( satisfying or ≠ OR @ 2 of these * represents ; 。 ： } ： • ×∞∗ ， ● － ∗ ∧ satisfying ℝ ↑ ， ∪ 下∞ ×¹∂ˣ 新θₙ? ∂← ⇒ ±₄ ） ^ ® = 0 * ！∪ † ≥ ⋅8 ∈ ˣ ） implies ∪. + ₙ … ^... » ∪ ∞ₙ∨∨ ₎ । ; ⊆ | [UNK]≤25ᵉⁿ ⊂ ℝ∨∨ । ′ ⊕≤ª₃ ∞ ⁿ । ‖ ₚ …∨ ; or¨ ª.. satisfying, ᵖªᵗ∪−↑ ‚∞ [UNK]← ª satisfying? − } * 。∪ • ★ⁿ← ₙₜ ₂∗ ∞ₙ ⇒ ω satisfying · ≤ ⊕ ）∪86 ‡ ≥ ₙ580ε¨ [UNK] > satisfy > equation ≡ ±32 ^ 256¹ । formulae 8364−20ω−01 = equations solving | solutions in area _ 5140A. ª039445338 * ; index location in red { mouse characters + ) and thus { name string - up space class... { string from input string element that means return type vector is \" row that type { * or b 」 → ^ + & 1 ; else then has sorted rows, so > AND ∗ matrix ≤ ⊂ ∗ᵀ vectors ≤ diagonal < operator ∗ if equals : ⋅ vector − ∨∧and ; if | ¬ₙ ∪ ε ~ ^ ≥1 + ∈ ª ; α ∈ ~ 5 ⊂ \\\\ 5 • 8 ⊂ δπ529ᵉb° > dπεβ → δBω ± > | brα - γ α → o < ~ 6ʰ } [UNK]σ, γ₄ } ″ ] { \" / / ω ′ θ₀ : \\\\ logi @ 14f [ uʔw°35₁ ^? bi ″ ′ | } 6⁴ν²ε₁ος } & 6λ⁷α ) 33 [ 1994 ¡ 87180, 2013 ; | © = 14\\'3232639. ] 23 \" PDF \" {. ~ page 34. / 050 < { condition! org ⟩ link notation, 2008 ª ; 2005 website application patent. - \\\\ image ″ / 0fttr64... 1d00 \" 2017 est293819 ′ # 213258032 [ 9 p 76 ] 18 20139 14 > 364 < । \" 8522 \\\\ 37½ hours 48 [SEP]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0) # batch_size = 1\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    predicted_index = torch.topk(prob, 100)[1][0][:,randint(0, 99)].numpy()\n",
    "    input_ids[len(input_ids) - 2] = predicted_index[len(input_ids[i:]) - 2]\n",
    "    \n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNHu0Uhf02FV"
   },
   "source": [
    "#### Feedback (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBZdRJeB02FW"
   },
   "source": [
    "Здесь вы можете оставить список опечаток из лекции или семинара:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "TNujGvky02FW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNp4g0rW02FX"
   },
   "source": [
    "Здесь вы можете оставить комментарии по лекции или семинару:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "DAA7GGwY02FY"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practice task 8, Advanced NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
